{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a4b33015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d496cd6",
   "metadata": {},
   "source": [
    "# Spark Application:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298fb551",
   "metadata": {},
   "source": [
    "### Read the data file into a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f514b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.cms.gov/files/zip/medicare-covid-19-data-snapshot-data-file.zip\n",
    "df1 = spark.read.csv('COVID-19-2021-02-20.csv', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8e4e63f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "root\n",
      " |-- Claims_Thru_Dt: string (nullable = true)\n",
      " |-- Measure_Level: string (nullable = true)\n",
      " |-- Measure_Element: string (nullable = true)\n",
      " |-- Measure_Unit: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(df1))\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321b6d0",
   "metadata": {},
   "source": [
    "### Produce a count of all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "545d2336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows 962\n"
     ]
    }
   ],
   "source": [
    "total = df1.count()\n",
    "print(\"Total Rows \" + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cb640234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455b211",
   "metadata": {},
   "source": [
    "### select the column(s) in the data which distinguishes different types of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "79d493ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------+\n",
      "|Measure_Level                                                   |\n",
      "+----------------------------------------------------------------+\n",
      "|COVID-19 Cases                                                  |\n",
      "|COVID-19 Cases by Age Group                                     |\n",
      "|COVID-19 Cases by Dual Status                                   |\n",
      "|COVID-19 Cases by Dual Status and Age Group                     |\n",
      "|COVID-19 Cases by Dual Status and Medicare Status               |\n",
      "|COVID-19 Cases by Dual Status and Race                          |\n",
      "|COVID-19 Cases by Dual Status and Sex                           |\n",
      "|COVID-19 Cases by Medicare Status                               |\n",
      "|COVID-19 Cases by Race                                          |\n",
      "|COVID-19 Cases by Race and Age Group                            |\n",
      "|COVID-19 Cases by Race and Medicare Status                      |\n",
      "|COVID-19 Cases by Race and Sex                                  |\n",
      "|COVID-19 Cases by Rural/Urban                                   |\n",
      "|COVID-19 Cases by Sex                                           |\n",
      "|COVID-19 Cases by State                                         |\n",
      "|COVID-19 Hospitalizations                                       |\n",
      "|COVID-19 Hospitalizations by Age Group                          |\n",
      "|COVID-19 Hospitalizations by Dual Status                        |\n",
      "|COVID-19 Hospitalizations by Dual Status and Age Group          |\n",
      "|COVID-19 Hospitalizations by Dual Status and Medicare Status    |\n",
      "|COVID-19 Hospitalizations by Dual Status and Race               |\n",
      "|COVID-19 Hospitalizations by Dual Status and Sex                |\n",
      "|COVID-19 Hospitalizations by Medicare Status                    |\n",
      "|COVID-19 Hospitalizations by Race                               |\n",
      "|COVID-19 Hospitalizations by Race and Age Group                 |\n",
      "|COVID-19 Hospitalizations by Race and Medicare Status           |\n",
      "|COVID-19 Hospitalizations by Race and Sex                       |\n",
      "|COVID-19 Hospitalizations by Rural/Urban                        |\n",
      "|COVID-19 Hospitalizations by Sex                                |\n",
      "|COVID-19 Hospitalizations by State                              |\n",
      "|COVID-19 Inpatient Discharge Status                             |\n",
      "|COVID-19 Inpatient Length of Stay                               |\n",
      "|COVID-19 Weekly Cases  (B97.29)                                 |\n",
      "|COVID-19 Weekly Cases (U07.1)                                   |\n",
      "|COVID-19 Weekly Hospitalizations  (B97.29)                      |\n",
      "|COVID-19 Weekly Hospitalizations (U07.1)                        |\n",
      "|Chronic Condition Prevalence Among FFS COVID-19 Hospitalizations|\n",
      "|Medicare Payments for FFS COVID-19 Hospitalizations             |\n",
      "|Other Respiratory Infection Weekly Cases (J80/J22/J988/J1289)   |\n",
      "+----------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SQL = \"\"\"SELECT DISTINCT Measure_Level\n",
    "FROM covid \n",
    "ORDER BY Measure_Level\"\"\"\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce91b9e",
   "metadata": {},
   "source": [
    "### Generate and output a small `DataFrame` containing all the \"overall case\" counts and their corresponding dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "20d02769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|Claims_Thru_Dt|overall_case|\n",
      "+--------------+------------+\n",
      "|02/20/2021    |3860957     |\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, CAST(SUM(Value) AS INT) overall_case\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases'\n",
    "  AND Measure_Element = 'Overall'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "GROUP BY Claims_Thru_Dt\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5077de",
   "metadata": {},
   "source": [
    "### Generate and output a small DataFrame containing all the \"overall case\" counts and their corresponding dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "06176fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|date      |overall_case|\n",
      "+----------+------------+\n",
      "|2021-02-20|40369       |\n",
      "|2021-02-13|60966       |\n",
      "|2021-02-06|91285       |\n",
      "|2021-01-30|114880      |\n",
      "|2021-01-23|138264      |\n",
      "|2021-01-16|162906      |\n",
      "|2021-01-09|191995      |\n",
      "|2021-01-02|199866      |\n",
      "|2020-12-26|157472      |\n",
      "|2020-12-19|174050      |\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT to_date(Measure_Element, 'MM/dd/yyyy') AS date, \n",
    "        CAST(SUM(Value) AS INT) overall_case\n",
    "FROM covid \n",
    "WHERE Measure_Level LIKE 'COVID-19 Weekly Cases%'\n",
    "GROUP BY date\n",
    "ORDER BY date DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76348e7",
   "metadata": {},
   "source": [
    "## Analyze a specific date:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b0ceb0",
   "metadata": {},
   "source": [
    "### Choose a single `Claims_Thru_Dt` with `Measure_Level` equal to `COVID-19 Cases by State` and `Measure_Unit` equal to `Beneficiary Count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "76c75dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+-----------------+------+\n",
      "|Claims_Thru_Dt|Measure_Level          |Measure_Unit     |Value |\n",
      "+--------------+-----------------------+-----------------+------+\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|86496 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|3023  |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|100260|\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|45366 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|338346|\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|40837 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|45536 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|11247 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|6191  |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|245845|\n",
      "+--------------+-----------------------+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, Measure_Level, Measure_Unit, Value\n",
    "FROM covid \n",
    "WHERE Claims_Thru_Dt = '02/20/2021' \n",
    "  AND Measure_Level = 'COVID-19 Cases by State' \n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdcceb5",
   "metadata": {},
   "source": [
    "### For that date, retrieve the `Value` for the `Overall` COVID-19 Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f512461d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "|Claims_Thru_Dt|Measure_Level |Measure_Element|Measure_Unit     |Value  |\n",
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "|02/20/2021    |COVID-19 Cases|Overall        |Beneficiary Count|3860957|\n",
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, Measure_Level, Measure_Element, Measure_Unit, Value\n",
    "FROM covid \n",
    "WHERE Claims_Thru_Dt = '02/20/2021'\n",
    "  AND Measure_Level = 'COVID-19 Cases' \n",
    "  AND Measure_Element = 'Overall'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3bc9a",
   "metadata": {},
   "source": [
    "### Sum the counts for every `COVID-19 Cases by State` `Measure_Element` that is an actual US state or territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5a7953b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|State               |overall_cases_by_state|\n",
      "+--------------------+----------------------+\n",
      "|California          |343631                |\n",
      "|Texas               |339923                |\n",
      "|New York            |312600                |\n",
      "|Florida             |251089                |\n",
      "|Pennsylvania        |173228                |\n",
      "|Illinois            |163114                |\n",
      "|New Jersey          |162266                |\n",
      "|Ohio                |156325                |\n",
      "|Georgia             |139561                |\n",
      "|North Carolina      |119582                |\n",
      "|Michigan            |115164                |\n",
      "|Arizona             |107569                |\n",
      "|Indiana             |101104                |\n",
      "|Tennessee           |95240                 |\n",
      "|Missouri            |95234                 |\n",
      "|Alabama             |94638                 |\n",
      "|Louisiana           |91744                 |\n",
      "|Massachusetts       |88850                 |\n",
      "|South Carolina      |80383                 |\n",
      "|Virginia            |76716                 |\n",
      "|Kentucky            |67455                 |\n",
      "|Oklahoma            |66603                 |\n",
      "|Wisconsin           |66300                 |\n",
      "|Mississippi         |66273                 |\n",
      "|Minnesota           |61824                 |\n",
      "|Maryland            |60116                 |\n",
      "|Arkansas            |52380                 |\n",
      "|Connecticut         |52124                 |\n",
      "|Iowa                |47180                 |\n",
      "|Puerto Rico         |45311                 |\n",
      "|Colorado            |45185                 |\n",
      "|Kansas              |41562                 |\n",
      "|Washington          |39197                 |\n",
      "|Nevada              |34742                 |\n",
      "|Nebraska            |27925                 |\n",
      "|Utah                |26160                 |\n",
      "|Idaho               |25862                 |\n",
      "|West Virginia       |25239                 |\n",
      "|New Mexico          |24591                 |\n",
      "|South Dakota        |23870                 |\n",
      "|Rhode Island        |21981                 |\n",
      "|Montana             |21213                 |\n",
      "|Oregon              |19342                 |\n",
      "|Delaware            |16449                 |\n",
      "|North Dakota        |16307                 |\n",
      "|New Hampshire       |13929                 |\n",
      "|District Of Columbia|12788                 |\n",
      "|Wyoming             |10999                 |\n",
      "|Maine               |9071                  |\n",
      "|Alaska              |5919                  |\n",
      "|Hawaii              |4213                  |\n",
      "|Vermont             |3481                  |\n",
      "|Virgin Islands      |2537                  |\n",
      "|Territories         |1652                  |\n",
      "|Missing Data        |1088                  |\n",
      "+--------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT Measure_Element as State, CAST(SUM(Value) AS INT) overall_cases_by_state\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases by State'\n",
    "GROUP BY State\n",
    "ORDER BY overall_cases_by_state DESC\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151e1f3",
   "metadata": {},
   "source": [
    "### Verify that the Overall total case count, minus the aggregation of all state/territory counts, is equal to the Missing Data count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "2c6b1597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Overall Cases:    4919693\n",
      "Total Overall By State: 4168829\n",
      "Missing Cases:           750864\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------#\n",
    "SQL1 = \"\"\"\n",
    "SELECT CAST(SUM(Value) AS INT) overall_cases\n",
    "FROM covid \n",
    "WHERE Measure_Element = 'Overall'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL1)\n",
    "res1 = df2.select('overall_cases').collect()[0]\n",
    "total_overall = int(res1[0])\n",
    "print(\"Total Overall Cases:    \" + str(total_overall))\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "SQL2 = \"\"\"\n",
    "SELECT CAST(SUM(Value) AS INT) overall_cases_by_state\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases by State'\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL2)\n",
    "res2 = df2.select('overall_cases_by_state').collect()[0]\n",
    "total_overall_by_state = int(res2[0])\n",
    "print(\"Total Overall By State: \" + str(total_overall_by_state))\n",
    "#-----------------------------------------------------#\n",
    "\n",
    "missing = total_overall - total_overall_by_state\n",
    "print(\"Missing Cases:           \" + str(missing))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fe910f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Overall By State: 4168829\n",
      "Missing: 307872\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ec4a7f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|missing|\n",
      "+-------+\n",
      "|23853  |\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT CAST(SUM(Value) AS INT) missing\n",
    "FROM covid \n",
    "WHERE Measure_Element = 'Missing Data'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7063db05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
