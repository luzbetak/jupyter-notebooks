{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d375f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb75107",
   "metadata": {},
   "source": [
    "## Spark application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "75b9bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file into a Spark DataFrame\n",
    "# https://www.cms.gov/files/zip/medicare-covid-19-data-snapshot-data-file.zip\n",
    "df1 = spark.read.csv('COVID-19-2021-02-20.csv', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2f18c677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "root\n",
      " |-- Claims_Thru_Dt: string (nullable = true)\n",
      " |-- Measure_Level: string (nullable = true)\n",
      " |-- Measure_Element: string (nullable = true)\n",
      " |-- Measure_Unit: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(df1))\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "52f32c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows 962\n"
     ]
    }
   ],
   "source": [
    "# Produce a count of all rows\n",
    "total = df1.count()\n",
    "print(\"Total Rows \" + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "941ad3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c72d8e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+--------------------+-----------------+-------+\n",
      "|Claims_Thru_Dt|Measure_Level          |Measure_Element     |Measure_Unit     |Value  |\n",
      "+--------------+-----------------------+--------------------+-----------------+-------+\n",
      "|02/20/2021    |COVID-19 Cases         |Overall             |Beneficiary Count|3860957|\n",
      "|02/20/2021    |COVID-19 Cases by State|Alabama             |Beneficiary Count|86496  |\n",
      "|02/20/2021    |COVID-19 Cases by State|Alaska              |Beneficiary Count|3023   |\n",
      "|02/20/2021    |COVID-19 Cases by State|Arizona             |Beneficiary Count|100260 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Arkansas            |Beneficiary Count|45366  |\n",
      "|02/20/2021    |COVID-19 Cases by State|California          |Beneficiary Count|338346 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Colorado            |Beneficiary Count|40837  |\n",
      "|02/20/2021    |COVID-19 Cases by State|Connecticut         |Beneficiary Count|45536  |\n",
      "|02/20/2021    |COVID-19 Cases by State|Delaware            |Beneficiary Count|11247  |\n",
      "|02/20/2021    |COVID-19 Cases by State|District Of Columbia|Beneficiary Count|6191   |\n",
      "+--------------+-----------------------+--------------------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample Data\n",
    "SQL = \"SELECT * FROM covid LIMIT 10\"\n",
    "df = spark.sql(SQL)\n",
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9865e5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|Claims_Thru_Dt|overall_case|\n",
      "+--------------+------------+\n",
      "|02/20/2021    |3860957     |\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate and output a small `DataFrame` containing all the \"overall case\" counts \n",
    "# and their corresponding dates\n",
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, CAST(SUM(Value) AS INT) overall_case\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases'\n",
    "  AND Measure_Element = 'Overall'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "GROUP BY Claims_Thru_Dt\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(SQL)\n",
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d22547a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|date      |overall_case|\n",
      "+----------+------------+\n",
      "|2021-02-20|40369       |\n",
      "|2021-02-13|60966       |\n",
      "|2021-02-06|91285       |\n",
      "|2021-01-30|114880      |\n",
      "|2021-01-23|138264      |\n",
      "|2021-01-16|162906      |\n",
      "|2021-01-09|191995      |\n",
      "|2021-01-02|199866      |\n",
      "|2020-12-26|157472      |\n",
      "|2020-12-19|174050      |\n",
      "|2020-12-12|170625      |\n",
      "|2020-12-05|179092      |\n",
      "|2020-11-28|136126      |\n",
      "|2020-11-21|143263      |\n",
      "|2020-11-14|128670      |\n",
      "|2020-11-07|96774       |\n",
      "|2020-10-31|85426       |\n",
      "|2020-10-24|69066       |\n",
      "|2020-10-17|61174       |\n",
      "|2020-10-10|56131       |\n",
      "|2020-10-03|50310       |\n",
      "|2020-09-26|43225       |\n",
      "|2020-09-19|42491       |\n",
      "|2020-09-12|37274       |\n",
      "|2020-09-05|43229       |\n",
      "|2020-08-29|44347       |\n",
      "|2020-08-22|46209       |\n",
      "|2020-08-15|50440       |\n",
      "|2020-08-08|53508       |\n",
      "|2020-08-01|67434       |\n",
      "|2020-07-25|65578       |\n",
      "|2020-07-18|69609       |\n",
      "|2020-07-11|65886       |\n",
      "|2020-07-04|59567       |\n",
      "|2020-06-27|49271       |\n",
      "|2020-06-20|41394       |\n",
      "|2020-06-13|39275       |\n",
      "|2020-06-06|45623       |\n",
      "|2020-05-30|40810       |\n",
      "|2020-05-23|46973       |\n",
      "|2020-05-16|47459       |\n",
      "|2020-05-09|48569       |\n",
      "|2020-05-02|64995       |\n",
      "|2020-04-25|55001       |\n",
      "|2020-04-18|54200       |\n",
      "|2020-04-11|53276       |\n",
      "|2020-04-04|42706       |\n",
      "|2020-03-28|19943       |\n",
      "|2020-03-21|6583        |\n",
      "|2020-03-14|1389        |\n",
      "|2020-03-07|700         |\n",
      "|2020-02-29|506         |\n",
      "|2020-02-22|550         |\n",
      "|2020-02-15|573         |\n",
      "|2020-02-08|599         |\n",
      "|2020-02-01|602         |\n",
      "|2020-01-25|578         |\n",
      "|2020-01-18|704         |\n",
      "|2020-01-11|731         |\n",
      "|2020-01-04|440         |\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate and output a small `DataFrame` containing all the \"overall case\" counts and their corresponding dates\n",
    "SQL = \"\"\"\n",
    "SELECT to_date(Measure_Element, 'MM/dd/yyyy') AS date, \n",
    "        CAST(SUM(Value) AS INT) overall_case\n",
    "FROM covid \n",
    "WHERE Measure_Level LIKE 'COVID-19 Weekly Cases%'\n",
    "GROUP BY date\n",
    "ORDER BY date DESC\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(SQL)\n",
    "df.show(99, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470532dd",
   "metadata": {},
   "source": [
    "## Analyze a specific date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "417f84fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+-----------------+------+\n",
      "|Claims_Thru_Dt|Measure_Level          |Measure_Unit     |Value |\n",
      "+--------------+-----------------------+-----------------+------+\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|86496 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|3023  |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|100260|\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|45366 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|338346|\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|40837 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|45536 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|11247 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|6191  |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|245845|\n",
      "+--------------+-----------------------+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose a single `Claims_Thru_Dt` with \n",
    "# `Measure_Level` equal to `COVID-19 Cases by State` \n",
    "# and `Measure_Unit` equal to `Beneficiary Count`\n",
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, Measure_Level, Measure_Unit, Value\n",
    "FROM covid \n",
    "WHERE Claims_Thru_Dt = '02/20/2021' \n",
    "  AND Measure_Level = 'COVID-19 Cases by State' \n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(SQL)\n",
    "df.show(99, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bf586b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "|Claims_Thru_Dt|Measure_Level |Measure_Element|Measure_Unit     |Value  |\n",
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "|02/20/2021    |COVID-19 Cases|Overall        |Beneficiary Count|3860957|\n",
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For that date, retrieve the `Value` for the `Overall` COVID-19 Cases\n",
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, Measure_Level, Measure_Element, Measure_Unit, Value\n",
    "FROM covid \n",
    "WHERE Claims_Thru_Dt = '02/20/2021'\n",
    "  AND Measure_Level = 'COVID-19 Cases' \n",
    "  AND Measure_Element = 'Overall'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(SQL)\n",
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c318bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|Claims_Thru_Dt|overall_case|\n",
      "+--------------+------------+\n",
      "|02/20/2021    |3867101     |\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, CAST(SUM(Value) AS INT) overall_case\n",
    "FROM covid \n",
    "WHERE \n",
    "    Measure_Level = 'COVID-19 Cases' AND \n",
    "    Measure_Element = 'Overall'\n",
    "GROUP BY Claims_Thru_Dt\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d631a21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|Measure_Element     |overall_case_by_state|\n",
      "+--------------------+---------------------+\n",
      "|Utah                |26160                |\n",
      "|Hawaii              |4213                 |\n",
      "|Minnesota           |61824                |\n",
      "|Ohio                |156325               |\n",
      "|Arkansas            |52380                |\n",
      "|Oregon              |19342                |\n",
      "|District Of Columbia|12788                |\n",
      "|Texas               |339923               |\n",
      "|North Dakota        |16307                |\n",
      "|Pennsylvania        |173228               |\n",
      "|Connecticut         |52124                |\n",
      "|Nebraska            |27925                |\n",
      "|Vermont             |3481                 |\n",
      "|Nevada              |34742                |\n",
      "|Puerto Rico         |45311                |\n",
      "|Washington          |39197                |\n",
      "|Illinois            |163114               |\n",
      "|Oklahoma            |66603                |\n",
      "|Missing Data        |1088                 |\n",
      "|Virgin Islands      |2537                 |\n",
      "|Delaware            |16449                |\n",
      "|Alaska              |5919                 |\n",
      "|New Mexico          |24591                |\n",
      "|West Virginia       |25239                |\n",
      "|Missouri            |95234                |\n",
      "|Rhode Island        |21981                |\n",
      "|Georgia             |139561               |\n",
      "|Montana             |21213                |\n",
      "|Michigan            |115164               |\n",
      "|Virginia            |76716                |\n",
      "|North Carolina      |119582               |\n",
      "|Wyoming             |10999                |\n",
      "|Kansas              |41562                |\n",
      "|New Jersey          |162266               |\n",
      "|Maryland            |60116                |\n",
      "|Alabama             |94638                |\n",
      "|Arizona             |107569               |\n",
      "|Iowa                |47180                |\n",
      "|Territories         |1652                 |\n",
      "|Massachusetts       |88850                |\n",
      "|Kentucky            |67455                |\n",
      "|Louisiana           |91744                |\n",
      "|Mississippi         |66273                |\n",
      "|New Hampshire       |13929                |\n",
      "|Tennessee           |95240                |\n",
      "|Florida             |251089               |\n",
      "|Indiana             |101104               |\n",
      "|Idaho               |25862                |\n",
      "|South Carolina      |80383                |\n",
      "|South Dakota        |23870                |\n",
      "|California          |343631               |\n",
      "|New York            |312600               |\n",
      "|Wisconsin           |66300                |\n",
      "|Colorado            |45185                |\n",
      "|Maine               |9071                 |\n",
      "+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT Measure_Element, CAST(SUM(Value) AS INT) overall_case_by_state\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases by State'\n",
    "GROUP BY Measure_Element\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634188f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
