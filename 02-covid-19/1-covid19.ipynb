{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c74512ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b3a7e",
   "metadata": {},
   "source": [
    "# Spark Application:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a346192",
   "metadata": {},
   "source": [
    "### Read the data file into a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "48bd5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.cms.gov/files/zip/medicare-covid-19-data-snapshot-data-file.zip\n",
    "df1 = spark.read.csv('COVID-19-2021-02-20.csv', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0eb9311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "root\n",
      " |-- Claims_Thru_Dt: string (nullable = true)\n",
      " |-- Measure_Level: string (nullable = true)\n",
      " |-- Measure_Element: string (nullable = true)\n",
      " |-- Measure_Unit: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(df1))\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f51cf3",
   "metadata": {},
   "source": [
    "### Produce a count of all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "633ac0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows 962\n"
     ]
    }
   ],
   "source": [
    "total = df1.count()\n",
    "print(\"Total Rows \" + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1eaf7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67c4ab",
   "metadata": {},
   "source": [
    "### select the column(s) in the data which distinguishes different types of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "77b5ce83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------+\n",
      "|Measure_Level                                                   |\n",
      "+----------------------------------------------------------------+\n",
      "|COVID-19 Cases                                                  |\n",
      "|COVID-19 Cases by Age Group                                     |\n",
      "|COVID-19 Cases by Dual Status                                   |\n",
      "|COVID-19 Cases by Dual Status and Age Group                     |\n",
      "|COVID-19 Cases by Dual Status and Medicare Status               |\n",
      "|COVID-19 Cases by Dual Status and Race                          |\n",
      "|COVID-19 Cases by Dual Status and Sex                           |\n",
      "|COVID-19 Cases by Medicare Status                               |\n",
      "|COVID-19 Cases by Race                                          |\n",
      "|COVID-19 Cases by Race and Age Group                            |\n",
      "|COVID-19 Cases by Race and Medicare Status                      |\n",
      "|COVID-19 Cases by Race and Sex                                  |\n",
      "|COVID-19 Cases by Rural/Urban                                   |\n",
      "|COVID-19 Cases by Sex                                           |\n",
      "|COVID-19 Cases by State                                         |\n",
      "|COVID-19 Hospitalizations                                       |\n",
      "|COVID-19 Hospitalizations by Age Group                          |\n",
      "|COVID-19 Hospitalizations by Dual Status                        |\n",
      "|COVID-19 Hospitalizations by Dual Status and Age Group          |\n",
      "|COVID-19 Hospitalizations by Dual Status and Medicare Status    |\n",
      "|COVID-19 Hospitalizations by Dual Status and Race               |\n",
      "|COVID-19 Hospitalizations by Dual Status and Sex                |\n",
      "|COVID-19 Hospitalizations by Medicare Status                    |\n",
      "|COVID-19 Hospitalizations by Race                               |\n",
      "|COVID-19 Hospitalizations by Race and Age Group                 |\n",
      "|COVID-19 Hospitalizations by Race and Medicare Status           |\n",
      "|COVID-19 Hospitalizations by Race and Sex                       |\n",
      "|COVID-19 Hospitalizations by Rural/Urban                        |\n",
      "|COVID-19 Hospitalizations by Sex                                |\n",
      "|COVID-19 Hospitalizations by State                              |\n",
      "|COVID-19 Inpatient Discharge Status                             |\n",
      "|COVID-19 Inpatient Length of Stay                               |\n",
      "|COVID-19 Weekly Cases  (B97.29)                                 |\n",
      "|COVID-19 Weekly Cases (U07.1)                                   |\n",
      "|COVID-19 Weekly Hospitalizations  (B97.29)                      |\n",
      "|COVID-19 Weekly Hospitalizations (U07.1)                        |\n",
      "|Chronic Condition Prevalence Among FFS COVID-19 Hospitalizations|\n",
      "|Medicare Payments for FFS COVID-19 Hospitalizations             |\n",
      "|Other Respiratory Infection Weekly Cases (J80/J22/J988/J1289)   |\n",
      "+----------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SQL = \"\"\"SELECT DISTINCT Measure_Level\n",
    "FROM covid \n",
    "ORDER BY Measure_Level\"\"\"\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea701e7e",
   "metadata": {},
   "source": [
    "### Generate and output a small `DataFrame` containing all the \"overall case\" counts and their corresponding dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fc336589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|Claims_Thru_Dt|overall_case|\n",
      "+--------------+------------+\n",
      "|02/20/2021    |3860957     |\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, CAST(SUM(Value) AS INT) overall_case\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases'\n",
    "  AND Measure_Element = 'Overall'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "GROUP BY Claims_Thru_Dt\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58733adf",
   "metadata": {},
   "source": [
    "### Generate and output a small DataFrame containing all the \"overall case\" counts and their corresponding dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9779cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|date      |overall_case|\n",
      "+----------+------------+\n",
      "|2021-02-20|40369       |\n",
      "|2021-02-13|60966       |\n",
      "|2021-02-06|91285       |\n",
      "|2021-01-30|114880      |\n",
      "|2021-01-23|138264      |\n",
      "|2021-01-16|162906      |\n",
      "|2021-01-09|191995      |\n",
      "|2021-01-02|199866      |\n",
      "|2020-12-26|157472      |\n",
      "|2020-12-19|174050      |\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT to_date(Measure_Element, 'MM/dd/yyyy') AS date, \n",
    "        CAST(SUM(Value) AS INT) overall_case\n",
    "FROM covid \n",
    "WHERE Measure_Level LIKE 'COVID-19 Weekly Cases%'\n",
    "GROUP BY date\n",
    "ORDER BY date DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dee18e",
   "metadata": {},
   "source": [
    "## Analyze a specific date:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb4e376",
   "metadata": {},
   "source": [
    "### Choose a single `Claims_Thru_Dt` with `Measure_Level` equal to `COVID-19 Cases by State` and `Measure_Unit` equal to `Beneficiary Count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2786c7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+-----------------+------+\n",
      "|Claims_Thru_Dt|Measure_Level          |Measure_Unit     |Value |\n",
      "+--------------+-----------------------+-----------------+------+\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|86496 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|3023  |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|100260|\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|45366 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|338346|\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|40837 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|45536 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|11247 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|6191  |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|245845|\n",
      "+--------------+-----------------------+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, Measure_Level, Measure_Unit, Value\n",
    "FROM covid \n",
    "WHERE Claims_Thru_Dt = '02/20/2021' \n",
    "  AND Measure_Level = 'COVID-19 Cases by State' \n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17573ea1",
   "metadata": {},
   "source": [
    "### For that date, retrieve the `Value` for the `Overall` COVID-19 Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fdc20371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "|Claims_Thru_Dt|Measure_Level |Measure_Element|Measure_Unit     |Value  |\n",
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "|02/20/2021    |COVID-19 Cases|Overall        |Beneficiary Count|3860957|\n",
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, Measure_Level, Measure_Element, Measure_Unit, Value\n",
    "FROM covid \n",
    "WHERE Claims_Thru_Dt = '02/20/2021'\n",
    "  AND Measure_Level = 'COVID-19 Cases' \n",
    "  AND Measure_Element = 'Overall'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e531861",
   "metadata": {},
   "source": [
    "### Sum the counts for every `COVID-19 Cases by State` `Measure_Element` that is an actual US state or territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "59a84871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|State               |overall_cases_by_state|\n",
      "+--------------------+----------------------+\n",
      "|California          |338346                |\n",
      "|Texas               |332177                |\n",
      "|New York            |304299                |\n",
      "|Florida             |245845                |\n",
      "|Pennsylvania        |167201                |\n",
      "|Illinois            |156213                |\n",
      "|New Jersey          |152911                |\n",
      "|Ohio                |150021                |\n",
      "|Georgia             |132114                |\n",
      "|North Carolina      |113988                |\n",
      "|Michigan            |109929                |\n",
      "|Arizona             |100260                |\n",
      "|Indiana             |93796                 |\n",
      "|Tennessee           |88830                 |\n",
      "|Missouri            |88171                 |\n",
      "|Alabama             |86496                 |\n",
      "|Massachusetts       |82730                 |\n",
      "|Louisiana           |82421                 |\n",
      "|South Carolina      |73728                 |\n",
      "|Virginia            |72055                 |\n",
      "|Wisconsin           |61204                 |\n",
      "|Kentucky            |60988                 |\n",
      "|Oklahoma            |58800                 |\n",
      "|Mississippi         |56937                 |\n",
      "|Minnesota           |56431                 |\n",
      "|Maryland            |54921                 |\n",
      "|Connecticut         |45536                 |\n",
      "|Arkansas            |45366                 |\n",
      "|Colorado            |40837                 |\n",
      "|Iowa                |40781                 |\n",
      "|Puerto Rico         |39984                 |\n",
      "|Washington          |36583                 |\n",
      "|Kansas              |35133                 |\n",
      "|Nevada              |29395                 |\n",
      "|Nebraska            |21773                 |\n",
      "|Utah                |21085                 |\n",
      "|West Virginia       |20587                 |\n",
      "|Idaho               |20117                 |\n",
      "|New Mexico          |19974                 |\n",
      "|Oregon              |17381                 |\n",
      "|South Dakota        |15353                 |\n",
      "|Rhode Island        |15210                 |\n",
      "|Montana             |14937                 |\n",
      "|Delaware            |11247                 |\n",
      "|New Hampshire       |10514                 |\n",
      "|North Dakota        |9347                  |\n",
      "|Maine               |7046                  |\n",
      "|District Of Columbia|6191                  |\n",
      "|Wyoming             |5859                  |\n",
      "|Hawaii              |3108                  |\n",
      "|Alaska              |3023                  |\n",
      "|Vermont             |2096                  |\n",
      "|Missing Data        |1003                  |\n",
      "|Virgin Islands      |423                   |\n",
      "|Territories         |256                   |\n",
      "+--------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT Measure_Element as State, \n",
    "       CAST(SUM(Value) AS INT) overall_cases_by_state\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases by State'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "GROUP BY State\n",
    "ORDER BY overall_cases_by_state DESC\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79a590d",
   "metadata": {},
   "source": [
    "### Verify that the Overall total case count, minus the aggregation of all state/territory counts, is equal to the Missing Data count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "383bcdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Overall Cases:    3860957\n",
      "Total Overall By State: 4168829\n",
      "Missing Cases:          -307872\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------#\n",
    "SQL1 = \"\"\"\n",
    "SELECT CAST(SUM(Value) AS INT) overall_cases\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases'\n",
    "  AND Measure_Element = 'Overall'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL1)\n",
    "res1 = df2.select('overall_cases').collect()[0]\n",
    "total_overall = int(res1[0])\n",
    "print(\"Total Overall Cases:    \" + str(total_overall))\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "SQL2 = \"\"\"\n",
    "SELECT CAST(SUM(Value) AS INT) overall_cases_by_state\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases by State'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL2)\n",
    "res2 = df2.select('overall_cases_by_state').collect()[0]\n",
    "total_overall_by_state = int(res2[0])\n",
    "print(\"Total Overall By State: \" + str(total_overall_by_state))\n",
    "#-----------------------------------------------------#\n",
    "\n",
    "missing = total_overall - total_overall_by_state\n",
    "print(\"Missing Cases:          \" + str(missing))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f66db68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|missing|\n",
      "+-------+\n",
      "|21800  |\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT CAST(SUM(Value) AS INT) missing\n",
    "FROM covid \n",
    "WHERE Measure_Element LIKE 'Missing%'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "0510fe03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|overall_cases_by_state|\n",
      "+----------------------+\n",
      "|3860957               |\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------#\n",
    "SQL2 = \"\"\"\n",
    "SELECT CAST(SUM(Value) AS INT) overall_cases_by_state\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases by State'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL2)\n",
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ff38d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
