{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "87119ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "import json\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c49fad9",
   "metadata": {},
   "source": [
    "# Spark Application:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec1f650",
   "metadata": {},
   "source": [
    "### Read the data file into a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "7a1c08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.cms.gov/files/zip/medicare-covid-19-data-snapshot-data-file.zip\n",
    "df1 = spark.read.csv('COVID-19-2021-02-20.csv', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "3bc400da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "root\n",
      " |-- Claims_Thru_Dt: string (nullable = true)\n",
      " |-- Measure_Level: string (nullable = true)\n",
      " |-- Measure_Element: string (nullable = true)\n",
      " |-- Measure_Unit: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(df1))\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab89d3",
   "metadata": {},
   "source": [
    "### Produce a count of all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a3b27a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows 962\n"
     ]
    }
   ],
   "source": [
    "total = df1.count()\n",
    "print(\"Total Rows \" + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "eb5527f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55150fa8",
   "metadata": {},
   "source": [
    "### select the column(s) in the data which distinguishes different types of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "29ef55df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------+\n",
      "|Measure_Level                                                   |\n",
      "+----------------------------------------------------------------+\n",
      "|COVID-19 Cases                                                  |\n",
      "|COVID-19 Cases by Age Group                                     |\n",
      "|COVID-19 Cases by Dual Status                                   |\n",
      "|COVID-19 Cases by Dual Status and Age Group                     |\n",
      "|COVID-19 Cases by Dual Status and Medicare Status               |\n",
      "|COVID-19 Cases by Dual Status and Race                          |\n",
      "|COVID-19 Cases by Dual Status and Sex                           |\n",
      "|COVID-19 Cases by Medicare Status                               |\n",
      "|COVID-19 Cases by Race                                          |\n",
      "|COVID-19 Cases by Race and Age Group                            |\n",
      "|COVID-19 Cases by Race and Medicare Status                      |\n",
      "|COVID-19 Cases by Race and Sex                                  |\n",
      "|COVID-19 Cases by Rural/Urban                                   |\n",
      "|COVID-19 Cases by Sex                                           |\n",
      "|COVID-19 Cases by State                                         |\n",
      "|COVID-19 Hospitalizations                                       |\n",
      "|COVID-19 Hospitalizations by Age Group                          |\n",
      "|COVID-19 Hospitalizations by Dual Status                        |\n",
      "|COVID-19 Hospitalizations by Dual Status and Age Group          |\n",
      "|COVID-19 Hospitalizations by Dual Status and Medicare Status    |\n",
      "|COVID-19 Hospitalizations by Dual Status and Race               |\n",
      "|COVID-19 Hospitalizations by Dual Status and Sex                |\n",
      "|COVID-19 Hospitalizations by Medicare Status                    |\n",
      "|COVID-19 Hospitalizations by Race                               |\n",
      "|COVID-19 Hospitalizations by Race and Age Group                 |\n",
      "|COVID-19 Hospitalizations by Race and Medicare Status           |\n",
      "|COVID-19 Hospitalizations by Race and Sex                       |\n",
      "|COVID-19 Hospitalizations by Rural/Urban                        |\n",
      "|COVID-19 Hospitalizations by Sex                                |\n",
      "|COVID-19 Hospitalizations by State                              |\n",
      "|COVID-19 Inpatient Discharge Status                             |\n",
      "|COVID-19 Inpatient Length of Stay                               |\n",
      "|COVID-19 Weekly Cases  (B97.29)                                 |\n",
      "|COVID-19 Weekly Cases (U07.1)                                   |\n",
      "|COVID-19 Weekly Hospitalizations  (B97.29)                      |\n",
      "|COVID-19 Weekly Hospitalizations (U07.1)                        |\n",
      "|Chronic Condition Prevalence Among FFS COVID-19 Hospitalizations|\n",
      "|Medicare Payments for FFS COVID-19 Hospitalizations             |\n",
      "|Other Respiratory Infection Weekly Cases (J80/J22/J988/J1289)   |\n",
      "+----------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SQL = \"\"\"SELECT DISTINCT Measure_Level\n",
    "FROM covid \n",
    "ORDER BY Measure_Level\"\"\"\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39622eb3",
   "metadata": {},
   "source": [
    "### Generate and output a small `DataFrame` containing all the \"overall case\" counts and their corresponding dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "14ba637c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|Claims_Thru_Dt|overall_case|\n",
      "+--------------+------------+\n",
      "|02/20/2021    |3860957     |\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, CAST(SUM(Value) AS INT) overall_case\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases'\n",
    "  AND Measure_Element = 'Overall'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "GROUP BY Claims_Thru_Dt\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc1a5a",
   "metadata": {},
   "source": [
    "### Generate and output a small DataFrame containing all the \"overall case\" counts and their corresponding dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "5593e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|date      |overall_case|\n",
      "+----------+------------+\n",
      "|2021-02-20|40369       |\n",
      "|2021-02-13|60966       |\n",
      "|2021-02-06|91285       |\n",
      "|2021-01-30|114880      |\n",
      "|2021-01-23|138264      |\n",
      "|2021-01-16|162906      |\n",
      "|2021-01-09|191995      |\n",
      "|2021-01-02|199866      |\n",
      "|2020-12-26|157472      |\n",
      "|2020-12-19|174050      |\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT to_date(Measure_Element, 'MM/dd/yyyy') AS date, \n",
    "        CAST(SUM(Value) AS INT) overall_case\n",
    "FROM covid \n",
    "WHERE Measure_Level LIKE 'COVID-19 Weekly Cases%'\n",
    "GROUP BY date\n",
    "ORDER BY date DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ebccdf",
   "metadata": {},
   "source": [
    "## Analyze a specific date:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee8d80c",
   "metadata": {},
   "source": [
    "### Choose a single `Claims_Thru_Dt` with `Measure_Level` equal to `COVID-19 Cases by State` and `Measure_Unit` equal to `Beneficiary Count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "876cb2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+-----------------+------+\n",
      "|Claims_Thru_Dt|Measure_Level          |Measure_Unit     |Value |\n",
      "+--------------+-----------------------+-----------------+------+\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|86496 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|3023  |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|100260|\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|45366 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|338346|\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|40837 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|45536 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|11247 |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|6191  |\n",
      "|02/20/2021    |COVID-19 Cases by State|Beneficiary Count|245845|\n",
      "+--------------+-----------------------+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, Measure_Level, Measure_Unit, Value\n",
    "FROM covid \n",
    "WHERE Claims_Thru_Dt = '02/20/2021' \n",
    "  AND Measure_Level = 'COVID-19 Cases by State' \n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31958cd",
   "metadata": {},
   "source": [
    "### For that date, retrieve the `Value` for the `Overall` COVID-19 Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "fdb31f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "|Claims_Thru_Dt|Measure_Level |Measure_Element|Measure_Unit     |Value  |\n",
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "|02/20/2021    |COVID-19 Cases|Overall        |Beneficiary Count|3860957|\n",
      "+--------------+--------------+---------------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT Claims_Thru_Dt, Measure_Level, Measure_Element, Measure_Unit, Value\n",
    "FROM covid \n",
    "WHERE Claims_Thru_Dt = '02/20/2021'\n",
    "  AND Measure_Level = 'COVID-19 Cases' \n",
    "  AND Measure_Element = 'Overall'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1afde97",
   "metadata": {},
   "source": [
    "### Sum the counts for every `COVID-19 Cases by State` `Measure_Element` that is an actual US state or territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "1226b905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|State               |overall_cases_by_state|\n",
      "+--------------------+----------------------+\n",
      "|California          |338346                |\n",
      "|Texas               |332177                |\n",
      "|New York            |304299                |\n",
      "|Florida             |245845                |\n",
      "|Pennsylvania        |167201                |\n",
      "|Illinois            |156213                |\n",
      "|New Jersey          |152911                |\n",
      "|Ohio                |150021                |\n",
      "|Georgia             |132114                |\n",
      "|North Carolina      |113988                |\n",
      "|Michigan            |109929                |\n",
      "|Arizona             |100260                |\n",
      "|Indiana             |93796                 |\n",
      "|Tennessee           |88830                 |\n",
      "|Missouri            |88171                 |\n",
      "|Alabama             |86496                 |\n",
      "|Massachusetts       |82730                 |\n",
      "|Louisiana           |82421                 |\n",
      "|South Carolina      |73728                 |\n",
      "|Virginia            |72055                 |\n",
      "|Wisconsin           |61204                 |\n",
      "|Kentucky            |60988                 |\n",
      "|Oklahoma            |58800                 |\n",
      "|Mississippi         |56937                 |\n",
      "|Minnesota           |56431                 |\n",
      "|Maryland            |54921                 |\n",
      "|Connecticut         |45536                 |\n",
      "|Arkansas            |45366                 |\n",
      "|Colorado            |40837                 |\n",
      "|Iowa                |40781                 |\n",
      "|Puerto Rico         |39984                 |\n",
      "|Washington          |36583                 |\n",
      "|Kansas              |35133                 |\n",
      "|Nevada              |29395                 |\n",
      "|Nebraska            |21773                 |\n",
      "|Utah                |21085                 |\n",
      "|West Virginia       |20587                 |\n",
      "|Idaho               |20117                 |\n",
      "|New Mexico          |19974                 |\n",
      "|Oregon              |17381                 |\n",
      "|South Dakota        |15353                 |\n",
      "|Rhode Island        |15210                 |\n",
      "|Montana             |14937                 |\n",
      "|Delaware            |11247                 |\n",
      "|New Hampshire       |10514                 |\n",
      "|North Dakota        |9347                  |\n",
      "|Maine               |7046                  |\n",
      "|District Of Columbia|6191                  |\n",
      "|Wyoming             |5859                  |\n",
      "|Hawaii              |3108                  |\n",
      "|Alaska              |3023                  |\n",
      "|Vermont             |2096                  |\n",
      "|Missing Data        |1003                  |\n",
      "|Virgin Islands      |423                   |\n",
      "|Territories         |256                   |\n",
      "+--------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL = \"\"\"\n",
    "SELECT Measure_Element as State, \n",
    "       CAST(SUM(Value) AS INT) overall_cases_by_state\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases by State'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "GROUP BY State\n",
    "ORDER BY overall_cases_by_state DESC\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df2.show(99, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0a052",
   "metadata": {},
   "source": [
    "### Verify that the Overall total case count, minus the aggregation of all state/territory counts, is equal to the Missing Data count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4f336b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Overall Cases:    3860957\n",
      "Total Overall By State: 3860957\n",
      "Missing Cases:          0\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------#\n",
    "SQL1 = \"\"\"\n",
    "SELECT CAST(SUM(Value) AS INT) overall_cases\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases'\n",
    "  AND Measure_Element = 'Overall'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL1)\n",
    "res1 = df2.select('overall_cases').collect()[0]\n",
    "total_overall = int(res1[0])\n",
    "print(\"Total Overall Cases:    \" + str(total_overall))\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "SQL2 = \"\"\"\n",
    "SELECT CAST(SUM(Value) AS INT) overall_cases_by_state\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases by State'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL2)\n",
    "res2 = df2.select('overall_cases_by_state').collect()[0]\n",
    "total_overall_by_state = int(res2[0])\n",
    "print(\"Total Overall By State: \" + str(total_overall_by_state))\n",
    "#-----------------------------------------------------#\n",
    "\n",
    "missing = total_overall - total_overall_by_state\n",
    "print(\"Missing Cases:          \" + str(missing))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98400c1",
   "metadata": {},
   "source": [
    "### Create a summary over all available dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f30d6d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'State': 'Iowa', 'Claims_Thru_Dt': '02/20/2021', 'count': 40781}\n",
      "{'State': 'Michigan', 'Claims_Thru_Dt': '02/20/2021', 'count': 109929}\n",
      "{'State': 'Missouri', 'Claims_Thru_Dt': '02/20/2021', 'count': 88171}\n",
      "{'State': 'Illinois', 'Claims_Thru_Dt': '02/20/2021', 'count': 156213}\n",
      "{'State': 'Kansas', 'Claims_Thru_Dt': '02/20/2021', 'count': 35133}\n",
      "{'State': 'Utah', 'Claims_Thru_Dt': '02/20/2021', 'count': 21085}\n",
      "{'State': 'Connecticut', 'Claims_Thru_Dt': '02/20/2021', 'count': 45536}\n",
      "{'State': 'Alabama', 'Claims_Thru_Dt': '02/20/2021', 'count': 86496}\n",
      "{'State': 'Wisconsin', 'Claims_Thru_Dt': '02/20/2021', 'count': 61204}\n",
      "{'State': 'Nebraska', 'Claims_Thru_Dt': '02/20/2021', 'count': 21773}\n",
      "{'State': 'New Mexico', 'Claims_Thru_Dt': '02/20/2021', 'count': 19974}\n",
      "{'State': 'Minnesota', 'Claims_Thru_Dt': '02/20/2021', 'count': 56431}\n",
      "{'State': 'Hawaii', 'Claims_Thru_Dt': '02/20/2021', 'count': 3108}\n",
      "{'State': 'Colorado', 'Claims_Thru_Dt': '02/20/2021', 'count': 40837}\n",
      "{'State': 'Nevada', 'Claims_Thru_Dt': '02/20/2021', 'count': 29395}\n",
      "{'State': 'Kentucky', 'Claims_Thru_Dt': '02/20/2021', 'count': 60988}\n",
      "{'State': 'Indiana', 'Claims_Thru_Dt': '02/20/2021', 'count': 93796}\n",
      "{'State': 'Missing Data', 'Claims_Thru_Dt': '02/20/2021', 'count': 1003}\n",
      "{'State': 'Territories', 'Claims_Thru_Dt': '02/20/2021', 'count': 256}\n",
      "{'State': 'Washington', 'Claims_Thru_Dt': '02/20/2021', 'count': 36583}\n",
      "{'State': 'Mississippi', 'Claims_Thru_Dt': '02/20/2021', 'count': 56937}\n",
      "{'State': 'Ohio', 'Claims_Thru_Dt': '02/20/2021', 'count': 150021}\n",
      "{'State': 'North Carolina', 'Claims_Thru_Dt': '02/20/2021', 'count': 113988}\n",
      "{'State': 'New York', 'Claims_Thru_Dt': '02/20/2021', 'count': 304299}\n",
      "{'State': 'Oregon', 'Claims_Thru_Dt': '02/20/2021', 'count': 17381}\n",
      "{'State': 'West Virginia', 'Claims_Thru_Dt': '02/20/2021', 'count': 20587}\n",
      "{'State': 'North Dakota', 'Claims_Thru_Dt': '02/20/2021', 'count': 9347}\n",
      "{'State': 'Massachusetts', 'Claims_Thru_Dt': '02/20/2021', 'count': 82730}\n",
      "{'State': 'New Jersey', 'Claims_Thru_Dt': '02/20/2021', 'count': 152911}\n",
      "{'State': 'Rhode Island', 'Claims_Thru_Dt': '02/20/2021', 'count': 15210}\n",
      "{'State': 'Delaware', 'Claims_Thru_Dt': '02/20/2021', 'count': 11247}\n",
      "{'State': 'Wyoming', 'Claims_Thru_Dt': '02/20/2021', 'count': 5859}\n",
      "{'State': 'Vermont', 'Claims_Thru_Dt': '02/20/2021', 'count': 2096}\n",
      "{'State': 'Puerto Rico', 'Claims_Thru_Dt': '02/20/2021', 'count': 39984}\n",
      "{'State': 'Arkansas', 'Claims_Thru_Dt': '02/20/2021', 'count': 45366}\n",
      "{'State': 'Georgia', 'Claims_Thru_Dt': '02/20/2021', 'count': 132114}\n",
      "{'State': 'Pennsylvania', 'Claims_Thru_Dt': '02/20/2021', 'count': 167201}\n",
      "{'State': 'South Carolina', 'Claims_Thru_Dt': '02/20/2021', 'count': 73728}\n",
      "{'State': 'Texas', 'Claims_Thru_Dt': '02/20/2021', 'count': 332177}\n",
      "{'State': 'District Of Columbia', 'Claims_Thru_Dt': '02/20/2021', 'count': 6191}\n",
      "{'State': 'California', 'Claims_Thru_Dt': '02/20/2021', 'count': 338346}\n",
      "{'State': 'Alaska', 'Claims_Thru_Dt': '02/20/2021', 'count': 3023}\n",
      "{'State': 'Maine', 'Claims_Thru_Dt': '02/20/2021', 'count': 7046}\n",
      "{'State': 'Maryland', 'Claims_Thru_Dt': '02/20/2021', 'count': 54921}\n",
      "{'State': 'Montana', 'Claims_Thru_Dt': '02/20/2021', 'count': 14937}\n",
      "{'State': 'Virginia', 'Claims_Thru_Dt': '02/20/2021', 'count': 72055}\n",
      "{'State': 'Oklahoma', 'Claims_Thru_Dt': '02/20/2021', 'count': 58800}\n",
      "{'State': 'Virgin Islands', 'Claims_Thru_Dt': '02/20/2021', 'count': 423}\n",
      "{'State': 'Idaho', 'Claims_Thru_Dt': '02/20/2021', 'count': 20117}\n",
      "{'State': 'Tennessee', 'Claims_Thru_Dt': '02/20/2021', 'count': 88830}\n",
      "{'State': 'New Hampshire', 'Claims_Thru_Dt': '02/20/2021', 'count': 10514}\n",
      "{'State': 'South Dakota', 'Claims_Thru_Dt': '02/20/2021', 'count': 15353}\n",
      "{'State': 'Florida', 'Claims_Thru_Dt': '02/20/2021', 'count': 245845}\n",
      "{'State': 'Louisiana', 'Claims_Thru_Dt': '02/20/2021', 'count': 82421}\n",
      "{'State': 'Arizona', 'Claims_Thru_Dt': '02/20/2021', 'count': 100260}\n"
     ]
    }
   ],
   "source": [
    "# Again, choose the `Measure_Level` equal to `COVID-19 Cases by State`\n",
    "# Create a data structure which produces the case data for each state, for each available date\n",
    "# Design and generate a nested JSON data structure which allows retrieval of a time-series of case data per state\n",
    "\n",
    "\n",
    "SQL = \"\"\"\n",
    "SELECT Measure_Element as State, \n",
    "       Claims_Thru_Dt,\n",
    "       CAST(SUM(Value) AS INT) count\n",
    "FROM covid \n",
    "WHERE Measure_Level = 'COVID-19 Cases by State'\n",
    "  AND Measure_Unit = 'Beneficiary Count'\n",
    "GROUP BY State, Claims_Thru_Dt\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(SQL)\n",
    "df_json = df2.toJSON()\n",
    "\n",
    "for row in df_json.collect():\n",
    "    line = json.loads(row) \n",
    "    print(line) \n",
    "    \n",
    "    \n",
    "# import pyspark.sql.functions as F\n",
    "\n",
    "# df3 = df2.groupBy(\n",
    "#     'State', 'Claims_Thru_Dt'\n",
    "# ).agg(\n",
    "#     F.collect_list(\n",
    "#         F.to_json(\n",
    "#             F.struct('State', 'Claims_Thru_Dt')\n",
    "#         )\n",
    "#     ).alias('values')\n",
    "# ).orderBy(\n",
    "#     'State', 'Claims_Thru_Dt'\n",
    "# )\n",
    "# print(df3.collect())\n",
    "\n",
    "# df2.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "c497bd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- user: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- event: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    MapType\n",
    ")\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "events_schema = StructType([\n",
    "    StructField('event_type', StringType(), True),\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('person_id', StringType(), True),\n",
    "    StructField('category', StringType(), True),\n",
    "    StructField('approved_content', StringType(), True),\n",
    "])\n",
    "\n",
    "events = [{\n",
    "    'event_type': 'click',\n",
    "    'id': '223',\n",
    "    'person_id': 201031940,\n",
    "    'category': 'Chronicles',\n",
    "    'approved_content': 1\n",
    "}]\n",
    "df = spark.createDataFrame(events, schema=events_schema)\n",
    "\n",
    "build_user_udf = udf(lambda id, person_id: {\n",
    "    'id': id,\n",
    "    'person_id': person_id\n",
    "}, MapType(StringType(), StringType()))\n",
    "\n",
    "build_event_udf = udf(lambda category, approved_content: {\n",
    "    'category': category,\n",
    "    'approved_content': approved_content\n",
    "}, MapType(StringType(), StringType()))\n",
    "\n",
    "nested_event_df = (\n",
    "    df\n",
    "    .withColumn('user', build_user_udf(df['id'], df['person_id']))\n",
    "    .withColumn('event', build_event_udf(df['category'], df['approved_content']))\n",
    "    .drop('id')\n",
    "    .drop('person_id')\n",
    "    .drop('category')\n",
    "    .drop('approved_content')\n",
    ")\n",
    "\n",
    "nested_event_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2eb90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
